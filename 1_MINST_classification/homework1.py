# -*- coding: utf-8 -*-
"""homework1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m6u1MPc7h82NJWqAe3z7fqNKwEaBs1d0
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 1.x
import tensorflow as tf  
hello = tf.constant('Hello, Tensorflow')  
sess = tf.Session()
print(sess.run(hello))

"""---


1ã€å¯¼å…¥ numpy åº“  \
2ã€å»ºç«‹ä¸€ä¸ªä¸€ç»´æ•°ç»„ aï¼Œåˆå§‹åŒ–ä¸º[4,5,6]  \
(1) è¾“å‡º a çš„ç±»åž‹ï¼ˆtypeï¼‰  \
(2) è¾“å‡º a çš„å„ç»´åº¦å¤§å°ï¼ˆshapeï¼‰ \
(3) è¾“å‡º a çš„ç¬¬ä¸€ä¸ªå…ƒç´ \
"""

import numpy as np
a=np.array([4,5,6])
print(type(a))
print(a.shape)
print(a[0])

"""---


3ã€å»ºç«‹ä¸€ä¸ªäºŒç»´æ•°ç»„ bï¼Œåˆå§‹åŒ–ä¸º[[4,5,6],[1,2,3]] \
(1) è¾“å‡º b çš„å„ç»´åº¦å¤§å°ï¼ˆshapeï¼‰ \
(2) è¾“å‡ºb[0,0],b[0,1],b[1,1]è¿™ä¸‰ä¸ªå…ƒç´ 
"""

b=np.array([[4,5,6],[1,2,3]])
print(b.shape)
print(b[0,0],b[0,1],b[1,1])

"""---
4ã€å»ºç«‹çŸ©é˜µ \
(1) å»ºç«‹ä¸€ä¸ªå¤§å°ä¸º3 Ã— 3çš„å…¨ 0 çŸ©é˜µ c \
(2) å»ºç«‹ä¸€ä¸ªå¤§å°ä¸º4 Ã— 5çš„å…¨ 1 çŸ©é˜µ d \
(3) å»ºç«‹ä¸€ä¸ªå¤§å°ä¸º4 Ã— 4çš„å•ä½çŸ©é˜µ e
"""

c=np.zeros((3,3))
d=np.ones((4,5))
e=np.eye(4)
print(c);print(d);print(e)

"""---


5ã€å»ºç«‹ä¸€ä¸ªæ•°ç»„ fï¼Œåˆå§‹åŒ–ä¸º[0,1,2,3,4,5,6,7,8,9,10,11]ï¼ˆarangeï¼‰ \
(1) è¾“å‡º f ä»¥åŠ f çš„å„ç»´åº¦å¤§å° \
"""

f=np.arange(12)
f

"""(2) å°† f çš„ shape æ”¹ä¸º3 Ã— 4ï¼ˆreshapeï¼‰"""

f=f.reshape(3,4)
f

"""(3) è¾“å‡º f ä»¥åŠ f çš„å„ç»´åº¦å¤§å°"""

f.shape

"""(4) è¾“å‡º f ç¬¬äºŒè¡Œï¼ˆf[1,âˆ¶]ï¼‰"""

f[1,:]

"""(5) è¾“å‡º f æœ€åŽä¸¤åˆ—ï¼ˆf[:,2:]ï¼‰"""

f[:,2:]

"""(6) è¾“å‡º f ç¬¬ä¸‰è¡Œæœ€åŽä¸€ä¸ªå…ƒç´ ï¼ˆä½¿ç”¨-1 è¡¨ç¤ºæœ€åŽä¸€ä¸ªå…ƒç´ ï¼‰"""

f[2,-1]

"""---
äºŒã€Tensorflow ç»ƒä¹ ï¼ˆæäº¤æ¯ä¸ªç»ƒä¹ çš„å®žçŽ°æ­¥éª¤æè¿°ä»¥åŠä¸‹é¢è¦æ±‚æäº¤çš„ç»“æžœï¼‰
 
1ã€çº¿æ€§å›žå½’ \
(1) ç”Ÿæˆè®­ç»ƒæ•°æ®
"""

num_observations=100
x=np.linspace(-3,3,num_observations)
y=np.sin(x)+np.random.uniform(-0.5,0.5,num_observations)
import matplotlib.pyplot as plt
plt.scatter(x,y)
plt.show()

"""(2)ä½¿ç”¨ tensorflow å®žçŽ°çº¿æ€§å›žå½’æ¨¡åž‹ï¼Œè®­ç»ƒå‚æ•°ð‘¤å’Œð‘ã€‚"""

n=len(x)

X = tf.placeholder("float") 
Y = tf.placeholder("float") 

W = tf.Variable(np.random.randn(), name = "W") 
b = tf.Variable(np.random.randn(), name = "b") 

learning_rate = 0.01
training_epochs = 1000

# åˆå§‹y_pred X*W
y_pred = tf.add(X*W, b) 

  
# losså‡½æ•°
cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n) 
  
# æ¢¯åº¦ä¸‹é™
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) 
  
# åˆå§‹åŒ–
init = tf.global_variables_initializer()
print('(3) è¾“å‡ºå‚æ•°ð‘¤ã€ð‘å’ŒæŸå¤±ã€‚ï¼ˆæäº¤è¿è¡Œç»“æžœï¼‰ ')
# è®­ç»ƒ
with tf.Session() as sess: 
      
    # åˆå§‹åŒ–
    sess.run(init) 
      
    # epochè®­ç»ƒ
    for epoch in range(training_epochs): 
          
        # éšæœºæ¢¯åº¦ä¸‹é™ï¼Œä¸€ä¸ªä¸€ä¸ªfeed
        for (_x, _y) in zip(x, y): 
            sess.run(optimizer, feed_dict = {X : _x, Y : _y}) 
          
        # æ˜¾ç¤ºw b
        if (epoch + 1) % 50 == 0: 
            c = sess.run(cost, feed_dict = {X : x, Y : y}) 
            print("Epoch", (epoch + 1), ": cost =", c, "W =", sess.run(W), "b =", sess.run(b)) 

    training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) 
    weight = sess.run(W) 
    bias = sess.run(b)

"""(3) è¾“å‡ºå‚æ•°ð‘¤ã€ð‘å’ŒæŸå¤±ã€‚ï¼ˆæäº¤è¿è¡Œç»“æžœï¼‰ \
(4) ç”»å‡ºé¢„æµ‹å›žå½’æ›²çº¿ä»¥åŠè®­ç»ƒæ•°æ®æ•£ç‚¹å›¾ï¼Œå¯¹æ¯”å›žå½’æ›²çº¿å’Œæ•£ç‚¹å›¾å¹¶åˆ†æžåŽŸå› ã€‚
ï¼ˆæäº¤å›¾ç‰‡åŠåˆ†æžï¼‰
"""

# é¢„æµ‹å€¼
predictions = weight * x + bias 
print("Training cost =", training_cost, "Weight =", weight, "bias =", bias, '\n')

# ç”»å›¾
plt.plot(x, y, 'ro', label ='Original data') 
plt.plot(x, predictions, label ='Fitted line') 
plt.title('Linear Regression Result') 
plt.legend() 
plt.show()

"""**ç­”ï¼š**
ä»Žå›žå½’æ›²çº¿å’Œæ•£ç‚¹å›¾æ¥çœ‹ï¼Œæ‹Ÿåˆæ•ˆæžœä¸å¥½ï¼Œå…¶åŽŸå› åœ¨äºŽæ•£ç‚¹æ•°æ®æœ¬èº«ä¸æ˜¯ç”±ä¸€ä¸ªçº¿æ€§å‡½æ•°å¾—åˆ°çš„ï¼Œæ•£ç‚¹æ•°æ®ç¬¦åˆéžçº¿æ€§å…³ç³»

---


2ã€çº¿æ€§å›žå½’ï¼ˆä½¿ç”¨å¤šé¡¹å¼å‡½æ•°å¯¹åŽŸå§‹æ•°æ®è¿›è¡Œå˜æ¢ï¼‰ \
(1) ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œæ•°æ®åŒä¸Š \
(2) ä½¿ç”¨ tensorflow å®žçŽ°çº¿æ€§å›žå½’æ¨¡åž‹ï¼Œè¿™é‡Œæˆ‘ä»¬å‡è®¾ð‘¦æ˜¯ð‘¥çš„ 3 æ¬¡å¤šé¡¹å¼
"""

num_observations=100
x=np.linspace(-3,3,num_observations)
y=np.sin(x)+np.random.uniform(-0.5,0.5,num_observations)

n=len(x)

X = tf.placeholder("float") 
Y = tf.placeholder("float") 

W1 = tf.Variable(np.random.randn(), name = "W1") 
W2 = tf.Variable(np.random.randn(), name = "W2")
W3 = tf.Variable(np.random.randn(), name = "W3")
b = tf.Variable(np.random.randn(), name = "b") 

learning_rate = 0.01
training_epochs = 1000

# åˆå§‹y_pred 
y_pred = tf.add(W1*X+W2*X**2+W3*X*X**2, b) 

  
# losså‡½æ•°
cost = tf.reduce_sum(tf.pow(y_pred-Y, 2)) / (2 * n) 
  
# æ¢¯åº¦ä¸‹é™
optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost) 
  
# åˆå§‹åŒ–
init = tf.global_variables_initializer()
print('(3) è¾“å‡ºå‚æ•°ð‘¤ã€ð‘å’ŒæŸå¤±ã€‚ï¼ˆæäº¤è¿è¡Œç»“æžœï¼‰ ')
# è®­ç»ƒ
with tf.Session() as sess: 
      
    # åˆå§‹åŒ–
    sess.run(init) 
      
    # epochè®­ç»ƒ
    for epoch in range(training_epochs): 
          
        # éšæœºæ¢¯åº¦ä¸‹é™ï¼Œä¸€ä¸ªä¸€ä¸ªfeed
        for (_x, _y) in zip(x, y): 
            sess.run(optimizer, feed_dict = {X : _x, Y : _y}) 
          
        # æ˜¾ç¤ºw b
        if (epoch + 1) % 50 == 0: 
            c = sess.run(cost, feed_dict = {X : x, Y : y}) 
            print("Epoch", (epoch + 1), ": cost =", c, "W =", sess.run([W1,W2,W3]), "b =", sess.run(b)) 

    training_cost = sess.run(cost, feed_dict ={X: x, Y: y}) 
    weight = sess.run([W1,W2,W3])
    bias = sess.run(b)

# é¢„æµ‹å€¼
predictions = weight[0]*x+weight[1]*x**2+weight[2]*x*x**2 + bias 
print("Training cost =", training_cost, "Weight =", weight, "bias =", bias, '\n')

# ç”»å›¾
plt.plot(x, y, 'ro', label ='Original data') 
plt.plot(x, predictions, label ='Fitted line') 
plt.title('Linear Regression Result') 
plt.legend() 
plt.show()

"""**ç­”ï¼š**
ä»Žå›žå½’æ›²çº¿å’Œæ•£ç‚¹å›¾æ¥çœ‹ï¼Œæ‹Ÿåˆæ•ˆæžœæŒºå¥½ï¼Œå…¶åŽŸå› åœ¨äºŽæ•£ç‚¹æ•°æ®ç¬¦åˆéžçº¿æ€§å…³ç³»ï¼Œç”¨äºŒæ¬¡å‡½æ•°å¯ä»¥æ‹Ÿåˆå‡ºè¾ƒå¥½çš„æ•ˆæžœ

---
3ã€Softmax åˆ†ç±» \
(1) èŽ·å– MNIST æ•°æ®é›†ï¼Œæ¯å¼ å›¾ç‰‡åƒç´ ä¸º28 Ã— 28
"""

from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)

learning_rate = 0.5
training_epochs = 2000

# Xæ˜¯ä¸€ä¸ªPlaceholder ,è¿™ä¸ªå€¼åŽç»­å†æ”¾å…¥è®©TFè®¡ç®—ï¼Œè¿™é‡Œæ˜¯ä¸€ä¸ª784ç»´ï¼Œä½†æ˜¯è®­ç»ƒæ•°é‡ä¸ç¡®å®šçš„ï¼ˆç”¨Noneè¡¨ç¤ºï¼‰çš„æµ®ç‚¹å€¼
X = tf.placeholder("float", [None,784 ])
Y = tf.placeholder("float", [None, 10])
# è®¾ç½®å¯¹åº”çš„æƒå€¼å’Œåç½®çš„è¡¨ç¤ºï¼ŒVariableä»£è¡¨ä¸€ä¸ªå˜é‡ï¼Œä¼šéšç€ç¨‹åºçš„ç”Ÿå‘½å‘¨æœŸåšä¸€ä¸ªæ”¹å˜
# éœ€è¦ç»™ä¸€ä¸ªåˆå§‹çš„å€¼ï¼Œè¿™é‡Œéƒ½å…¨éƒ¨è¡¨ç¤ºä¸º0
W = tf.Variable(tf.zeros([784, 10]))
b = tf.Variable(tf.zeros([10]))

y_pred = tf.nn.softmax(tf.matmul(X, W) + b)

#äº¤å‰ç†µåŽ»è¡¡é‡ reduce_sum ç´¯åŠ 
cross_entropy = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(y_pred), reduction_indices=[1]))
#è®­ç»ƒçš„æ­¥éª¤ï¼Œå‘Šè¯‰tfï¼Œç”¨æ¢¯åº¦ä¸‹é™æ³•åŽ»ä¼˜åŒ–ï¼Œå­¦ä¹ çŽ‡æ˜¯0.5ï¼Œç›®çš„æ˜¯æœ€å°åŒ–äº¤å‰ç†µ
train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cross_entropy)
# åˆ°ç›®å‰ä¸ºæ­¢ï¼Œæˆ‘ä»¬å·²ç»å®šä¹‰å®Œäº†æ‰€æœ‰çš„æ­¥éª¤ï¼Œä¸‹é¢å°±éœ€è¦åˆå§‹åŒ–è¿™ä¸ªè®­ç»ƒæ­¥éª¤äº†ï¼Œé¦–å…ˆåˆå§‹åŒ–æ‰€æœ‰å˜é‡ï¼ˆä¹‹å‰å®šä¹‰çš„å˜é‡ï¼‰
init = tf.initialize_all_variables()


sess=tf.Session()
      
# åˆå§‹åŒ–
sess.run(init) 
      
#è®°å½•
cost_list=[]
accur_list=[]
best_cost=[]
best_accur=[]
correct_prediction = tf.equal(tf.argmax(Y,1), tf.argmax(y_pred,1))
accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
temp_bc=1;temp_ba=0
# epochè®­ç»ƒ
for epoch in range(training_epochs): 
          

    # éšæœºæ¢¯åº¦ä¸‹é™ï¼Œä¸€ä¸ªä¸€ä¸ªfeed
    batch_xs, batch_ys = mnist.train.next_batch(100,shuffle=True)
    sess.run(train_step, feed_dict = {X : batch_xs, Y : batch_ys}) 
    c = sess.run(cross_entropy, feed_dict = {X : batch_xs, Y : batch_ys})
    a = sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels})   
    cost_list.append(c)
    accur_list.append(a)
    if (temp_bc>c):
      best_cost.append(c)
      temp_bc=c
    else:
      best_cost.append(temp_bc)
    if (temp_ba<a):
      best_accur.append(a)
      temp_ba=a
    else:
      best_accur.append(temp_ba)
    # æ˜¾ç¤ºw b
    if (epoch + 1) % 50 == 0: 
        c = sess.run(cross_entropy, feed_dict = {X : batch_xs, Y : batch_ys}) 
        print("Epoch", (epoch + 1), ": cost =", c, "b =", sess.run(b)) 
    

print(sess.run(accuracy, feed_dict={X: mnist.test.images, Y: mnist.test.labels}))

"""---

(3) ç”»å‡ºè®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹çš„å‡†ç¡®çŽ‡éšè¿­ä»£æ¬¡æ•°å˜åŒ–å›¾ï¼Œç”»å‡ºè®­ç»ƒå’Œæµ‹è¯•è¿‡ç¨‹çš„æŸ
å¤±éšè¿­ä»£æ¬¡æ•°å˜åŒ–å›¾ã€‚ï¼ˆæäº¤æœ€ç»ˆåˆ†ç±»ç²¾åº¦ã€åˆ†ç±»æŸå¤±ä»¥åŠä¸¤å¼ å˜åŒ–å›¾ï¼‰
"""

fig,ax=plt.subplots(2,1)
ax[0].plot(range(training_epochs) ,accur_list)
ax[1].plot(range(training_epochs),cost_list)
plt.show()

fig,ax=plt.subplots(2,1)
ax[0].plot(best_accur,'r-')
ax[1].plot(best_cost,'b-')